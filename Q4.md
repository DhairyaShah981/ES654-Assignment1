
<h3> Theoretical time complexity of the code </h3> 
The time complexity of the program can be different based on the input types and can be different based on whether we give the max_depth value or not. Let us assume that the input set has M attributes and there are a total of N samples. 

- Case one: The input set contains real values. 

	Now, the time complexity of the information gain function is - 
	If the function is given an input series of size N, it will have to calculate the information
	gain for all the possible splits and return the split with the maximum information gain.
	For a given split the function takes an $O(N)$ time to calculator the information gain for an 
	Input size of N. Now since there are a total of $(N-1)$ possible splits. Thus the function 
	has a time complexity of $O(N^2)$.

	Now in each of the iterations we will have to iterate through each of the column, pass it 
	to the information gain function and find the column which gives the highest information gain up on the split. Since there are M columns, in the worst case
	scenario we will have to pass all of the M columns to the function in each of the recursions. Additionally, there can be a total of N iteration in the worse
	case scenario. 

	Thus, the complexity of the program in the case when real inputs are given is equal to $O(N^3M)$

- Case two: The input set contains discrete values.

	Now the time complexity of the information gain function is - 
	If the function is given an input series of size N, it will have to go through the entire dataset an order of $N$ times and thus the complexity is $N$ in this
	case. Since each column is passed through the information gain function, each of the recursions will take order *O(NM)* times in the worst case scenario. 

	Finding  the number of iterations: 

	- In the case that the product of all unique attributes from each of the columns is lesser than the sample size($N$):
		The total number of all possible combinations for a row in the input set is equal to the product of all the unique attributes from each of the columns.
		Thus, in the case that this value is less than the total number of samples, the maximum possible iteration will be one less than that product value
		even in the worst case scenario. 

	- In the case that the product of all unique attributes from each of the columns is greater than the sample size($N$):
	In such a case, since the decision tree is built in such a way that every non leaf node has at least two children, the maximum number of nodes and hence the
	number of recursions is equal to $(N-1)$. Thus in the worst case worst case scenario, the code will through a total of $(N-1)$ iterations. 

	Thus, in the case of discrete inputs, the time complexity is equal to $O(min(X,N)MN)$, where $X$ is the product of the number of discrete values in each column
	. 
<h5> Practical results: </h5> 

<u>Plots:<u/> 
1. Real input, Real output:
	- for constructing the tree: 
	
	![riro_learning](https://user-images.githubusercontent.com/76052389/214154535-53a90916-c86d-454a-9bcc-07de5e930788.jpg)
	
	- for predicting the output: 
	
	![riro_prediction](https://user-images.githubusercontent.com/76052389/214154577-91479702-598a-434d-a881-e87ace20083e.jpg)
	
2. Real input, Discrete output:
	- for constructing the tree: 
	
	![rido_prediction](https://user-images.githubusercontent.com/76052389/214154656-d2cf9457-a633-42f8-82e5-17272c4e28ff.jpg)
	
	- for predicting the output: 
	
	![rido_learning](https://user-images.githubusercontent.com/76052389/214154735-9351da6d-fb7f-483b-aabf-2401e3eab288.jpg)
	
3. Discrete input, Real output:
	- for constructing the tree:
	
	![diro_learning](https://user-images.githubusercontent.com/76052389/214154852-5d3bc404-68e3-4da0-a062-83c79f442c47.jpg)
	
	- for predicting the output:
	
	![diro_prediction](https://user-images.githubusercontent.com/76052389/214155340-cf38feab-cd03-48df-8c6f-ad7c4854c68d.jpg)
	
4. Discrete input, Discrete output:
	- for constructing the tree: 
	
	![dido_learning](https://user-images.githubusercontent.com/76052389/214154923-a3701961-4fa5-4207-90ee-e3578eb2d6af.jpg)
	
	- for predicting the output: 
	
	![dido_prediction](https://user-images.githubusercontent.com/76052389/214154941-ec8bbb3a-edcb-42e1-b413-a47acad0889d.jpg)

	
